{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phisan-chula/Chula_InSAR/blob/main/download_insar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_f1Lva5-CA"
      },
      "source": [
        "**DownLoad-InSAR** : Download ASF Hyp3/GAMMA InSAR products from ASF/Vertex by accesss Hyp3 processing service. Downloaded products will be put in the specfied directory within GoogleDrive named WORKING_DIR and JOB_NAME><br>\n",
        "<pre>Jan,2018 : Isara Chaowuttisuk (Tle) Phichaowuttisuk@hotmail.com\n",
        "         : Phisan Santitamnont (phisan.chula@gmail.com)\n",
        "Reference :\n",
        "1. [hyp3-docs](https://hyp3-docs.asf.alaska.edu/using/sdk/)\n",
        "2. [asf-search](https://search.asf.alaska.edu/#/?searchType=Custom%20Products&resultsLoaded=true&granule=e514b1d1-f848-47c6-8071-c28056bc4974) <bre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAQaXPEF2I3C"
      },
      "source": [
        "**1. Mount GoogleCoLab to user's GoogleDrive and define NETRC_CRED, WORKING_DIR, JOB_NAME, DEBUG_PROD in section 4.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EGg6grk2ybS",
        "outputId": "14a96c22-855f-4738-a220-c6ddbfa07451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount GoogleCoLab to user's GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_O-IMjtzR_a"
      },
      "source": [
        "**2.Build InSAR/Hyp3 VM :** take some minutes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHNNmH3VhKHx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "conda_path = ''\n",
        "try:\n",
        "    conda_path = !which conda\n",
        "finally:\n",
        "    print('')\n",
        "\n",
        "if (len(conda_path) == 0):\n",
        "    print('installing miniconda')\n",
        "    !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n",
        "    !conda update conda -y -q\n",
        "    !source /usr/local/etc/profile.d/conda.sh\n",
        "    !conda init \n",
        "    !conda install -n root _license -y -q\n",
        "else:\n",
        "    print('found miniconda')\n",
        "\n",
        "conda_envs = !conda env list\n",
        "res = [i for i in conda_envs if 'InSAR' in i]\n",
        "if (len(res) == 0):\n",
        "    print('not found InSAR env', len(res))\n",
        "    !conda create -y -q --name InSAR python=3.9\n",
        "else:\n",
        "    print('found InSAR env', len(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D-JybFy6hsqy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "source activate InSAR\n",
        "conda install -c conda-forge asf_search -y\n",
        "conda install -c conda-forge hyp3_sdk asf_search pandas geopandas -y\n",
        "\n",
        "python\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages')\n",
        "\n",
        "print(\"Python version\", sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s-k0USW6sbl4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6Apxk51zYh3"
      },
      "source": [
        "**4. Create Job_Download function on InSAR VM :** modifty your NETRC_CRED, WORKING_DIR, JOB_NAME, DEBUG_PROD accordingly..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3FFUDJwR-mZZ",
        "outputId": "6e639b09-d55c-47f5-fc6a-8bfbc1bdd405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting job_download.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile job_download.py\n",
        "#####################################################################\n",
        "NETRC_CRED  = '/content/drive/MyDrive/.netrc'      # user name and password in NETRC\n",
        "WORKING_DIR = '/content/drive/MyDrive/InSAR-DOH/'  # existing directory within GoogleDrive\n",
        "HYP3_NODE   =  'urs.earthdata.nasa.gov'\n",
        "JOB_NAME    = 'DES_CMI_PYO_2021'    #  job name as submitted to ASF Hyp3 INSAR_GAMMA JOB\n",
        "DEBUG_PROD  = -1 #  -1 download all products, no debug ;  1,2,3,.... few trials \n",
        "#####################################################################\n",
        "\n",
        "import os, re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import netrc\n",
        "import urllib.request\n",
        "\n",
        "from hyp3_sdk import HyP3\n",
        "\n",
        "def FindJobs( JOB_TYPE='INSAR_GAMMA' ):\n",
        "    batch = hyp3.find_jobs()\n",
        "    batch = hyp3.refresh(batch)\n",
        "    df_job = None\n",
        "    for job in batch.jobs:\n",
        "        job1 =  job.to_dict().copy()\n",
        "        if job1['job_type']==JOB_TYPE:\n",
        "            job2 =  job1.pop('job_parameters',None).copy()\n",
        "            job3 = {**job1,**job2}\n",
        "            df = pd.DataFrame.from_dict( job3, orient='index' ).transpose()\n",
        "            #print( df)\n",
        "            if df_job is None:\n",
        "                df_job = df\n",
        "            else:\n",
        "                df_job = pd.concat( [ df_job, df ], ignore_index=True )\n",
        "            del df\n",
        "        else:\n",
        "            print( 'skipping ....', job1['job_type'] )\n",
        "    return df_job\n",
        "#######################################################################\n",
        "netrc = netrc.netrc(NETRC_CRED)\n",
        "USER,_,PASSWD = netrc.authenticators( HYP3_NODE )\n",
        "hyp3 = HyP3(username=USER, password=PASSWD)\n",
        "# print(hyp3.my_info())\n",
        "\n",
        "project_path = WORKING_DIR\n",
        "folder_out_path = os.path.join(project_path, JOB_NAME )\n",
        "os.makedirs(folder_out_path, exist_ok=True)\n",
        "\n",
        "df_job = FindJobs()\n",
        "df_job = df_job[(df_job['name']==JOB_NAME)&(df_job.status_code=='SUCCEEDED') ]\n",
        "for idx, row in df_job.iterrows():\n",
        "    if DEBUG_PROD == 0: break\n",
        "    url = row['files'][0]['url']\n",
        "    fn = row['files'][0]['filename']\n",
        "    outpath = os.path.join(folder_out_path, fn)\n",
        "    if os.path.exists(outpath) or os.path.exists(outpath.split('.zip')[0]):\n",
        "        print('[{}/{}] {} already exists, skip downloading.'.format(DEBUG_PROD, len(df_job), outpath ) )\n",
        "    else:\n",
        "        try:     \n",
        "          urllib.request.urlretrieve(url, outpath)\n",
        "          print('[{}/{}] {}... downloaded.'.format(DEBUG_PROD, len(df_job), outpath))\n",
        "        except:\n",
        "          print('***ERROR*** retrieving ...', url )\n",
        "    DEBUG_PROD -= 1\n",
        "\n",
        "print('*** end job_download() ***')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thx5b309ojps"
      },
      "source": [
        "**5. Execute Job_Dowload with automatic resume ....**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGX9oW1XRyEx"
      },
      "outputs": [],
      "source": [
        "!source activate InSAR; python job_download.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "download-insar.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}